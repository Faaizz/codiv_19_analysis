{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Steps\n",
    "1. Update all data\n",
    "1. Process pipeline\n",
    "1. Slope calculation\n",
    "1. Visual board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Update all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Output: b'Updating 4070863d..56f5b3ce\\nFast-forward\\n .../csse_covid_19_daily_reports/08-29-2020.csv     | 3951 ++++++++++++\\n .../csse_covid_19_daily_reports_us/08-29-2020.csv  |   59 +\\n .../time_series_covid19_confirmed_US.csv           | 6682 ++++++++++----------\\n .../time_series_covid19_confirmed_global.csv       |  534 +-\\n .../time_series_covid19_deaths_US.csv              | 6682 ++++++++++----------\\n .../time_series_covid19_deaths_global.csv          |  534 +-\\n .../time_series_covid19_recovered_global.csv       |  508 +-\\n 7 files changed, 11480 insertions(+), 7470 deletions(-)\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports/08-29-2020.csv\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports_us/08-29-2020.csv\\n'\nError: b'From https://github.com/CSSEGISandData/COVID-19\\n   4070863d..56f5b3ce  master     -> origin/master\\n   8e52e500..3b64cfae  web-data   -> origin/web-data\\n'\nUpdated data for all 37 states in Nigeria.\n"
    }
   ],
   "source": [
    "# %load ../src/data/get_data.py\n",
    "# Imports\n",
    "import os, subprocess, json\n",
    "\n",
    "# Environmental Variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# HTTP Client\n",
    "import requests\n",
    "\n",
    "# For parsing and sifting through HTML\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# Load environmental variables specified in .env\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def get_johns_hopkings():\n",
    "    \"\"\" Update data from Johns Hopkings (GITHUB)\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    \"\"\"\n",
    "\n",
    "    # GIT PULL\n",
    "    cmd= \"git pull\"\n",
    "    cmd_wd= \"../data/raw/JH_dataset/COVID-19\"\n",
    "    # Pull from Git repo\n",
    "    git_proc= subprocess.Popen(\n",
    "        cmd,\n",
    "        cwd=cmd_wd, shell=True, \n",
    "        stdout= subprocess.PIPE, stderr= subprocess.PIPE\n",
    "    )\n",
    "\n",
    "    proc_timeout= 600\n",
    "    try:\n",
    "        (git_proc_out, git_proc_err)= git_proc.communicate(timeout=proc_timeout)\n",
    "    except TimeoutError:\n",
    "        print(\"Update operation on Johns Hopkins Dataset from GITHUB failed...\\n\")\n",
    "\n",
    "    print(\"Output: \" + str(git_proc_out))\n",
    "    print(\"Error: \" + str(git_proc_err))\n",
    "\n",
    "\n",
    "\n",
    "def get_current_nigeria():\n",
    "    \"\"\" Update data from Nigeria Centre for Disease Control (NCDC)\n",
    "\n",
    "    Update data from NCDC via webscraping\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    \"\"\"\n",
    "    # WEB SCRAPING\n",
    "    # Pull page on COVID-19\n",
    "    page= requests.get(\"https://covid19.ncdc.gov.ng/\")\n",
    "    # Parse HTML\n",
    "    parsed_page= BeautifulSoup(page.content, 'html.parser')\n",
    "    # Pull Table\n",
    "    html_table= parsed_page.find('table')\n",
    "    # Pull table rows\n",
    "    table_rows= html_table.find_all('tr')\n",
    "\n",
    "    # Table Header\n",
    "    table_header= dict()\n",
    "    # Table data\n",
    "    table_data=[]\n",
    "\n",
    "    # Loop through table rows\n",
    "    for idx,row in enumerate(table_rows):\n",
    "        # Table headers in first row\n",
    "        if(idx==0):\n",
    "            # Pull column headers\n",
    "            col_headers= row.find_all('th')\n",
    "            # Make a dictionary of column headers\n",
    "            table_headers= { idx:col_header.get_text(strip=True) for idx,col_header in enumerate(col_headers) }\n",
    "        \n",
    "        # Table data\n",
    "        # Get row columns\n",
    "        row_cols= row.find_all('td')\n",
    "        # Get data body into list\n",
    "        row_data= [ col.get_text(strip=True) for col in row_cols ]\n",
    "        # Append col to row list\n",
    "        table_data.append(row_data)\n",
    "\n",
    "        # Make data into Pandas Frame\n",
    "    pd_table= pd.DataFrame(table_data)\n",
    "    # Remove empty rows\n",
    "    pd_table= pd_table.dropna()\n",
    "    # Insert column names\n",
    "    pd_table= pd_table.rename(columns=table_headers)\n",
    "\n",
    "    # Drop column \"No. of Cases (on admission)\"\n",
    "    pd_table= pd_table.drop([\"No. of Cases (on admission)\"], axis=1)\n",
    "    # Rename \"No. of Cases (Lab Confirmed)\"\n",
    "    pd_table= pd_table.rename(\n",
    "        columns={\"No. of Cases (Lab Confirmed)\": \"No. of Cases\"}\n",
    "    )\n",
    "\n",
    "    # UPDATE DATASET\n",
    "    pd_table.to_csv(\n",
    "        \"../data/processed/NCDC.csv\", sep=\";\", \n",
    "    )\n",
    "    print(\"Updated data for all {0} states in Nigeria.\".format(pd_table.shape[0]))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    get_johns_hopkings()\n",
    "    get_current_nigeria()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Process pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Number of rows stored: 58786.\n"
    }
   ],
   "source": [
    "# %load ../src/data/process_JH_data.py\n",
    "# Imports\n",
    "import os, subprocess, json\n",
    "from datetime import datetime\n",
    "\n",
    "# Environmental Variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# HTTP Client\n",
    "import requests\n",
    "# For parsing and sifting through HTML\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def store_relational_model():\n",
    "    \"\"\" Process Johns Hopkings data into a Relational dataset\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    \"\"\"\n",
    "    # Read data into dataframe\n",
    "    data_path= \"../data/raw/JH_dataset/COVID-19/\" + \\\n",
    "        \"csse_covid_19_data/csse_covid_19_time_series/\" + \\\n",
    "        \"time_series_covid19_confirmed_global.csv\"\n",
    "    pd_raw= pd.read_csv(data_path)\n",
    "\n",
    "    # Create DataFrame\n",
    "    rel_fr= pd.DataFrame(pd_raw)\n",
    "\n",
    "    # Discard Lat and Long columns\n",
    "    rel_fr= rel_fr.drop([\"Lat\", \"Long\"], axis=1)\n",
    "    \n",
    "    # Set NaN to 'no'. Important for indexing\n",
    "    rel_fr= rel_fr.fillna('no')\n",
    "\n",
    "    # Rename columns for convienence\n",
    "    rel_fr= rel_fr.rename(\n",
    "        columns={\"Province/State\": \"state\", \"Country/Region\": \"country\"}\n",
    "        )\n",
    "    # Index data by (state, country)\n",
    "    rel_fr= rel_fr.set_index([\"state\", \"country\"])\n",
    "    # Make dates row headers and state/country column headers\n",
    "    rel_fr= rel_fr.T\n",
    "    # Stack the data by dates and reset indices\n",
    "    rel_fr= rel_fr.stack([\"state\", \"country\"]).reset_index()\n",
    "    # Set new column names\n",
    "    rel_fr= rel_fr.rename(columns={\"level_0\": \"date\", 0:\"confirmed\"})\n",
    "\n",
    "    # Convert date to datetime type\n",
    "    rel_fr[\"date\"]= rel_fr.date.astype(\"datetime64[ns]\")\n",
    "\n",
    "    # UPDATE DATASET\n",
    "    rel_fr.to_csv(\n",
    "        \"../data/processed/COVID_relational_full.csv\", sep=\";\",index=False\n",
    "    )\n",
    "    print(\"Number of rows stored: {0}.\".format(rel_fr.shape[0]))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    store_relational_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Filtering and Doubling Rate Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "index       date state   country  confirmed  confirmed_filtered  \\\n58781  58781 2020-08-29    no  Barbados      170.0               168.6   \n58782  58782 2020-08-29    no   Belarus    71523.0             71539.8   \n58783  58783 2020-08-29    no   Belgium    84599.0             84550.8   \n58784  58784 2020-08-29    no   Albania     9279.0              9310.2   \n58785  58785 2020-08-29    no  Zimbabwe     6406.0              6418.0   \n\n       confirmed_DR  confirmed_filtered_DR  \n58781     66.800000             128.692308  \n58782    398.573557             363.255601  \n58783    152.897179             160.788749  \n58784     93.731293              70.178899  \n58785    111.614035             114.224417  \n"
    }
   ],
   "source": [
    "# %load ../src/features/build_features.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from scipy import signal\n",
    "\n",
    "# Create Linear Regression Model\n",
    "reg= linear_model.LinearRegression(fit_intercept= True)  \n",
    "\n",
    "\n",
    "def get_doubling_rate_via_regression(in_array):\n",
    "    \"\"\" Approximate the doubling time using linear regression.\n",
    "\n",
    "    3 datapoints are used to approximate the number of days \n",
    "    it takes for the number of infected people to double at each point.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    in_array: List/ numpy Array\n",
    "        input data\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    doubling_time: double\n",
    "    \"\"\"\n",
    "    \n",
    "    # Assert output vector is 3 datapoints long\n",
    "    assert len(in_array)==3\n",
    " \n",
    "    y= np.array(in_array)\n",
    "    # Calculate slope using central difference\n",
    "    X= np.arange(-1,2).reshape(-1,1)\n",
    "\n",
    "    # Fit data\n",
    "    reg.fit(X,y)\n",
    "    intercept= reg.intercept_\n",
    "    slope= reg.coef_\n",
    "\n",
    "    return intercept/slope\n",
    "\n",
    "\n",
    "def rolling_regression(df_input, col=\"confirmed\"):\n",
    "    \"\"\" Roll over entries to approximate the doubling time using linear regression.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    df_input: pandas DataFrame\n",
    "        input data\n",
    "    col: string\n",
    "        key to column which holds data entries\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    result: pandas Series\n",
    "    \"\"\"\n",
    "    \n",
    "    days_back= 3\n",
    "    \n",
    "    result= df_input[col].rolling(\n",
    "            window=days_back,\n",
    "            min_periods=days_back\n",
    "        ).apply(get_doubling_rate_via_regression, raw=False)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def savgol_filter(df_input, col='confirmed', window=5):\n",
    "    \"\"\" Filter data using savgol filter.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    df_input: pandas DataFrame\n",
    "        input data\n",
    "    col: string\n",
    "        key to column which holds data entries\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    df_result: pandas DataFrame\n",
    "        df_input with additional column with name col+\"_filtered\"\n",
    "    \"\"\"\n",
    "\n",
    "    window=5\n",
    "    degree=1\n",
    "\n",
    "    df_result=df_input\n",
    "\n",
    "    filter_in= df_input[col].fillna(0)\n",
    "    result= signal.savgol_filter(\n",
    "            np.array(filter_in), window, degree\n",
    "        )\n",
    "\n",
    "    df_result[col+ \"_filtered\"]= result\n",
    "    return df_result\n",
    "    \n",
    "\n",
    "def calc_filtered_data(df_input, filter_on='confirmed'):\n",
    "    \"\"\" Filter data using savgol filter and return merged dataframe\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    df_input: pandas DataFrame\n",
    "        input data\n",
    "    filter_on: string\n",
    "        key to column which holds data entries on which to filter\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    df_out: pandas DataFrame\n",
    "        df_input with additional column with name filter_on+\"_filtered\"\n",
    "    \"\"\"\n",
    "\n",
    "    # Assertion\n",
    "    must_contain= set(['state', 'country', filter_on])\n",
    "    assert must_contain.issubset(set(df_input.columns))\n",
    "\n",
    "    pd_filt_res= df_input.groupby(['state','country']).apply(savgol_filter, filter_on).reset_index()\n",
    "    df_out= pd.merge(df_input, pd_filt_res[['index', filter_on+'_filtered']], on=['index'], how='left')\n",
    "\n",
    "    return df_out\n",
    "\n",
    "\n",
    "def calc_doubling_rate(df_input, double_on='confirmed'):\n",
    "    \"\"\" Calculate doubling rate using linear regression and return merged dataframe\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    df_input: pandas DataFrame\n",
    "        input data\n",
    "    double_on: string\n",
    "        key to column which holds data entries\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    df_out: pandas DataFrame\n",
    "        df_input with additional column with name double_on+\"_filtered\"\n",
    "    \"\"\"\n",
    "\n",
    "    # Assertion\n",
    "    must_contain= set(['state', 'country', double_on])\n",
    "    assert must_contain.issubset(set(df_input.columns))\n",
    "\n",
    "    pd_doub_res= df_input.groupby(['state','country']).apply(rolling_regression, double_on).reset_index()\n",
    "    pd_doub_res= pd_doub_res.rename(columns={'level_2': 'index', double_on: double_on+\"_DR\"})\n",
    "\n",
    "    df_out= pd.merge(df_input, pd_doub_res[['index', double_on+'_DR']], on=['index'], how='left')\n",
    "\n",
    "    return df_out\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test data\n",
    "    test_data= np.array([2,4,6])\n",
    "    # Expected result= 2\n",
    "    result= get_doubling_rate_via_regression(test_data)\n",
    "    assert(int(result[0]) == 2)\n",
    "\n",
    "    pd_JH_rel= pd.read_csv(\n",
    "            '../data/processed/COVID_relational_full.csv', \n",
    "            sep=';', parse_dates=[0]\n",
    "        )\n",
    "    pd_JH_rel= pd_JH_rel.sort_values('date', ascending=True).reset_index(drop=True)\n",
    "    pd_JH_rel= pd_JH_rel.reset_index()\n",
    "\n",
    "    pd_res= calc_filtered_data(pd_JH_rel, filter_on='confirmed')\n",
    "    pd_res= calc_doubling_rate(pd_res, double_on='confirmed')\n",
    "    pd_res= calc_doubling_rate(pd_res, double_on='confirmed_filtered')\n",
    "    \n",
    "    \n",
    "    # Cleanup confirmed_filtered_DR\n",
    "    DR_mask= pd_res['confirmed']>100\n",
    "    pd_res['confirmed_filtered_DR']= pd_res['confirmed_filtered_DR'].where(DR_mask, other=np.NaN)\n",
    "\n",
    "    # Save\n",
    "    pd_res.to_csv('../data/processed/COVID_final_set.csv', sep=';', index=False)\n",
    "    \n",
    "    print(pd_res.tail())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Visual Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Working Directory: /home/faaizz/Desktop/SS_2020/EDS/personal/ads_covid-19/notebooks\nRunning on http://127.0.0.1:8050/\nDebugger PIN: 987-571-423\n * Serving Flask app \"__main__\" (lazy loading)\n * Environment: production\n\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n\u001b[2m   Use a production WSGI server instead.\u001b[0m\n * Debug mode: on\n"
    }
   ],
   "source": [
    "# %load ../src/visualization/visualize.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as dhtml\n",
    "from dash.dependencies import Input, Output\n",
    "\n",
    "import os\n",
    "\n",
    "print(\"Working Directory: {0}\".format(os.getcwd()))\n",
    "\n",
    "df_JH_data= pd.read_csv('../data/processed/COVID_final_set.csv', sep=';')\n",
    "\n",
    "# Create figure\n",
    "fig= go.Figure()\n",
    "\n",
    "# Create Dash App\n",
    "app= dash.Dash()\n",
    "\n",
    "# Create App layout\n",
    "app.layout= dhtml.Div([\n",
    "    dcc.Markdown(\"\"\"\n",
    "    # COVID-19 Data Analysis\n",
    "\n",
    "    Goal of this project is to learn data science methods by applying cross industry \n",
    "    standard process for data management (CRISP-DM).\n",
    "\n",
    "    \"\"\"),\n",
    "\n",
    "    dcc.Markdown(\"\"\"\n",
    "    ## Multi-Select Country for visualization\n",
    "    \"\"\"),\n",
    "\n",
    "    dcc.Dropdown(\n",
    "        id='country_dropdown',\n",
    "        options=[ {'label': each, 'value': each} for each in df_JH_data['country'].unique() ],\n",
    "        # Default selections\n",
    "        value= ['Nigeria', 'Germany', 'Italy'],\n",
    "        multi=True\n",
    "    ),\n",
    "\n",
    "    dcc.Markdown(\"\"\"\n",
    "    ## Select visualization timeline\n",
    "    \"\"\"),\n",
    "\n",
    "    dcc.Dropdown(\n",
    "        id= 'visual_time',\n",
    "        options=[\n",
    "            {'label': 'Timeline Confirmed', 'value': 'confirmed'},\n",
    "            {'label': 'Timeline Confirmed Filtered', 'value': 'confirmed_filtered'},\n",
    "            {'label': 'Timeline Doubling Rate', 'value': 'confirmed_DR'},\n",
    "            {'label': 'Timeline Doubling Rate Filtered', 'value': 'confirmed_filtered_DR'}\n",
    "        ],\n",
    "        value='confirmed',\n",
    "        multi=False\n",
    "    ),\n",
    "\n",
    "    dcc.Graph(figure=fig, id='main_figure')\n",
    "])\n",
    "\n",
    "\n",
    "# Add callback for Dropdown\n",
    "\n",
    "# Callback wrapper\n",
    "@app.callback(\n",
    "    Output(\"main_figure\", \"figure\"),\n",
    "    [\n",
    "        Input(\"country_dropdown\", \"value\"),\n",
    "        Input('visual_time', 'value')\n",
    "    ]\n",
    ")\n",
    "# Callback function\n",
    "def update_fig(selected_countries, visual_name):\n",
    "\n",
    "    # Title\n",
    "    if('DR' in visual_name):\n",
    "        my_yaxis={\n",
    "            'type': 'log',\n",
    "            'title': 'Approximated doubling rate over 3 days (the larger the number, the better)'\n",
    "        }\n",
    "    \n",
    "    else: \n",
    "        my_yaxis={\n",
    "            'type': 'log',\n",
    "            'title': 'Confirmed cases (source: Johns Hopkings, log-scale)'\n",
    "        }\n",
    "\n",
    "    #Traces\n",
    "    traces= []\n",
    "    for country in selected_countries:\n",
    "\n",
    "        # Selected country mask\n",
    "        df_plot= df_JH_data[df_JH_data['country']== country]\n",
    "\n",
    "        # Aggregate country-wide data\n",
    "        if 'DR' in visual_name:\n",
    "            # If doubling rate is being calculated, use the mean over the states\n",
    "            df_plot= df_plot[[\n",
    "                'date', 'state', 'country', 'confirmed', 'confirmed_filtered', \n",
    "                'confirmed_DR', 'confirmed_filtered_DR'\n",
    "                ]].groupby(['country', 'date']).agg(np.mean).reset_index()\n",
    "\n",
    "        else:\n",
    "            # Otherwise, sum up the values for all states\n",
    "            df_plot= df_plot[[\n",
    "                'date', 'state', 'country', 'confirmed', 'confirmed_filtered', \n",
    "                'confirmed_DR', 'confirmed_filtered_DR'\n",
    "                ]].groupby(['country', 'date']).agg(np.sum).reset_index()\n",
    "\n",
    "\n",
    "        # Add a trace\n",
    "        traces.append(\n",
    "            {\n",
    "                \"x\": df_plot.date,\n",
    "                \"y\": df_plot[visual_name],\n",
    "                \"mode\":\"markers+lines\",\n",
    "                \"opacity\": 0.8,\n",
    "                \"name\": country\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Layout\n",
    "    fig_design= dict(\n",
    "        width=1280,\n",
    "        height=720,\n",
    "        xaxis_title=\"Timeline\",\n",
    "        xaxis={\n",
    "            \"tickangle\": -75,\n",
    "            \"nticks\": 20,\n",
    "            \"tickfont\": dict(size=14, color=\"#7f7f7f\")\n",
    "        },\n",
    "        yaxis=my_yaxis\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"data\": traces,\n",
    "        \"layout\": fig_design\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    app.run_server(debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('EDS2020': conda)",
   "language": "python",
   "name": "python_defaultSpec_1598799714921"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}